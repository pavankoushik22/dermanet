{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Importing required libraries and DL tools","metadata":{"_uuid":"0123112d74eeb4ec6b6fec77b0bd61d655d4c90a"}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport tensorflow\nfrom tensorflow.keras.layers import Dense, Dropout\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.metrics import categorical_crossentropy\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.model_selection import train_test_split\nimport itertools\nimport shutil\nimport matplotlib.pyplot as plt\n%matplotlib inline","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#creating a main directory for dataset\nbase_dir = 'base_dir'\nos.mkdir(base_dir)\n\n#creating a sub directory for trainable dataset\ntrain_dir = os.path.join(base_dir, 'train_dir')\nos.mkdir(train_dir)\n\n\n#creating a sub directory for validation dataset\nval_dir = os.path.join(base_dir, 'val_dir')\nos.mkdir(val_dir)\n\n# create new folders inside train_dir for different classes\nnv = os.path.join(train_dir, 'nv')\nos.mkdir(nv)\nmel = os.path.join(train_dir, 'mel')\nos.mkdir(mel)\nbkl = os.path.join(train_dir, 'bkl')\nos.mkdir(bkl)\nbcc = os.path.join(train_dir, 'bcc')\nos.mkdir(bcc)\nakiec = os.path.join(train_dir, 'akiec')\nos.mkdir(akiec)\nvasc = os.path.join(train_dir, 'vasc')\nos.mkdir(vasc)\ndf = os.path.join(train_dir, 'df')\nos.mkdir(df)\n\n\n\n# create new folders inside val_dir for different classes\nnv = os.path.join(val_dir, 'nv')\nos.mkdir(nv)\nmel = os.path.join(val_dir, 'mel')\nos.mkdir(mel)\nbkl = os.path.join(val_dir, 'bkl')\nos.mkdir(bkl)\nbcc = os.path.join(val_dir, 'bcc')\nos.mkdir(bcc)\nakiec = os.path.join(val_dir, 'akiec')\nos.mkdir(akiec)\nvasc = os.path.join(val_dir, 'vasc')\nos.mkdir(vasc)\ndf = os.path.join(val_dir, 'df')\nos.mkdir(df)","metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# accessing meta data about the obtained dataset","metadata":{"_uuid":"2d1ad811c0a8f664ddced070a5ef26b865f00aea"}},{"cell_type":"code","source":"df_data = pd.read_csv('../input/HAM10000_metadata.csv')\n\ndf_data.head()","metadata":{"_uuid":"3ea0c1af8fbcc93fc12602054b6009e63741ef20","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# pre processing starts here","metadata":{"_uuid":"c2a9555bf64087f32b969291540bafef4d97012e"}},{"cell_type":"code","source":"# this will tell us how many images are associated with each lesion_id\ndf = df_data.groupby('lesion_id').count()\n\n# now we filter out lesion_id's that have only one image associated with it\ndf = df[df['image_id'] == 1]\n\ndf.reset_index(inplace=True)\n\ndf.head()","metadata":{"_uuid":"8564ce3c6a082f3fb9043969315632e659e2d552","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# here we identify lesion_id's that have duplicate images and those that have only\n# one image.\n\ndef identify_duplicates(x):\n    \n    unique_list = list(df['lesion_id'])\n    \n    if x in unique_list:\n        return 'no_duplicates'\n    else:\n        return 'has_duplicates'\n    \n# create a new colum that is a copy of the lesion_id column\ndf_data['duplicates'] = df_data['lesion_id']\n# apply the function to this new column\ndf_data['duplicates'] = df_data['duplicates'].apply(identify_duplicates)\n\ndf_data.head()","metadata":{"_uuid":"0628e82a9138f190521335f522e988f9785e7dd0","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_data['duplicates'].value_counts()","metadata":{"_uuid":"965d7fc76d23c602c172222f4a8640d5e16436f2","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# now we filter out images that don't have duplicates\ndf = df_data[df_data['duplicates'] == 'no_duplicates']\n\ndf.shape","metadata":{"_uuid":"0104a8a4152bbf6852ad9eb93224fbb6f4f211b9","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# now we create a val set using df because we are sure that none of these images\n# have augmented duplicates in the train set\ny = df['dx']\n\n_, df_val = train_test_split(df, test_size=0.17, random_state=101, stratify=y)\n\ndf_val.shape","metadata":{"_uuid":"7edc1c31818d9b6dd29e55e41014f8593cd356e6","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_val['dx'].value_counts()","metadata":{"_uuid":"2c9c408d463ee74d9fefb7302b7b71444419c3a3","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# seperating train and validation data","metadata":{"_uuid":"e6f965d27cd3c8e5885e86f9a552a9c2c2011715"}},{"cell_type":"code","source":"# This set will be df_data excluding all rows that are in the val set\n\n# This function identifies if an image is part of the train\n# or val set.\ndef identify_val_rows(x):\n    # create a list of all the lesion_id's in the val set\n    val_list = list(df_val['image_id'])\n    \n    if str(x) in val_list:\n        return 'val'\n    else:\n        return 'train'\n\n# identify train and val rows\n\n# create a new colum that is a copy of the image_id column\ndf_data['train_or_val'] = df_data['image_id']\n# apply the function to this new column\ndf_data['train_or_val'] = df_data['train_or_val'].apply(identify_val_rows)\n   \n# filter out train rows\ndf_train = df_data[df_data['train_or_val'] == 'train']\n\n\nprint(len(df_train))\nprint(len(df_val))","metadata":{"_uuid":"dcfe6eb7863e213365b8f3046e1903dadd886629","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train['dx'].value_counts()","metadata":{"_uuid":"f810f03b32434397edf392c20ebacb2a1749c2cc","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_val['dx'].value_counts()","metadata":{"_uuid":"158bfb4f40ebacaa8780faf6db4432d27416caa4","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# transfer images to their respective folders based on the meta data","metadata":{"_uuid":"8585548179889fbeacfd2d8358db0b19c69785b7"}},{"cell_type":"code","source":"# Set the image_id as the index in df_data\ndf_data.set_index('image_id', inplace=True)\n\n# Get a list of images in each of the two folders\nfolder_1 = os.listdir('../input/ham10000_images_part_1')\nfolder_2 = os.listdir('../input/ham10000_images_part_2')\n\n# Get a list of train and val images\ntrain_list = list(df_train['image_id'])\nval_list = list(df_val['image_id'])\n\n\n\n# Transfer the train images\n\nfor image in train_list:\n    \n    fname = image + '.jpg'\n    label = df_data.loc[image,'dx']\n    \n    if fname in folder_1:\n        # source path to image\n        src = os.path.join('../input/ham10000_images_part_1', fname)\n        # destination path to image\n        dst = os.path.join(train_dir, label, fname)\n        # copy the image from the source to the destination\n        shutil.copyfile(src, dst)\n\n    if fname in folder_2:\n        # source path to image\n        src = os.path.join('../input/ham10000_images_part_2', fname)\n        # destination path to image\n        dst = os.path.join(train_dir, label, fname)\n        # copy the image from the source to the destination\n        shutil.copyfile(src, dst)\n\n\n# Transfer the val images\n\nfor image in val_list:\n    \n    fname = image + '.jpg'\n    label = df_data.loc[image,'dx']\n    \n    if fname in folder_1:\n        # source path to image\n        src = os.path.join('../input/ham10000_images_part_1', fname)\n        # destination path to image\n        dst = os.path.join(val_dir, label, fname)\n        # copy the image from the source to the destination\n        shutil.copyfile(src, dst)\n\n    if fname in folder_2:\n        # source path to image\n        src = os.path.join('../input/ham10000_images_part_2', fname)\n        # destination path to image\n        dst = os.path.join(val_dir, label, fname)\n        # copy the image from the source to the destination\n        shutil.copyfile(src, dst)\n        ","metadata":{"_uuid":"e0f57aa1192f21359614189df8dd6db1e7ceab64","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# check how many train images we have in each folder","metadata":{"_uuid":"8596f38a449c3fca7a34853aaf328eeb397cd6df"}},{"cell_type":"code","source":"\nprint(len(os.listdir('base_dir/train_dir/nv')))\nprint(len(os.listdir('base_dir/train_dir/mel')))\nprint(len(os.listdir('base_dir/train_dir/bkl')))\nprint(len(os.listdir('base_dir/train_dir/bcc')))\nprint(len(os.listdir('base_dir/train_dir/akiec')))\nprint(len(os.listdir('base_dir/train_dir/vasc')))\nprint(len(os.listdir('base_dir/train_dir/df')))","metadata":{"_uuid":"c98788e0418de6a1565cfa0cae278313b00afb26","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# check how many val images we have in each folder","metadata":{"_uuid":"4aa5a31d22828d7a97a2739a8d144195e0f0a509"}},{"cell_type":"code","source":"print(len(os.listdir('base_dir/val_dir/nv')))\nprint(len(os.listdir('base_dir/val_dir/mel')))\nprint(len(os.listdir('base_dir/val_dir/bkl')))\nprint(len(os.listdir('base_dir/val_dir/bcc')))\nprint(len(os.listdir('base_dir/val_dir/akiec')))\nprint(len(os.listdir('base_dir/val_dir/vasc')))\nprint(len(os.listdir('base_dir/val_dir/df')))","metadata":{"_uuid":"5ac7eabc9280ef1933df4c0e85f8d48eee1363a5","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Now we augment given data since obtained data is limited","metadata":{"_uuid":"44f0eeae5112158af6cfd052c28bb8d8d4b06a3b"}},{"cell_type":"code","source":"# note that we are not augmenting class 'nv'\nclass_list = ['mel','bkl','bcc','akiec','vasc','df']\n\nfor item in class_list:\n    \n    # We are creating temporary directories here because we delete these directories later\n    # create a base dir\n    aug_dir = 'aug_dir'\n    os.mkdir(aug_dir)\n    # create a dir within the base dir to store images of the same class\n    img_dir = os.path.join(aug_dir, 'img_dir')\n    os.mkdir(img_dir)\n\n    # Choose a class\n    img_class = item\n\n    # list all images in that directory\n    img_list = os.listdir('base_dir/train_dir/' + img_class)\n\n    # Copy images from the class train dir to the img_dir e.g. class 'mel'\n    for fname in img_list:\n            # source path to image\n            src = os.path.join('base_dir/train_dir/' + img_class, fname)\n            # destination path to image\n            dst = os.path.join(img_dir, fname)\n            # copy the image from the source to the destination\n            shutil.copyfile(src, dst)\n\n\n    # point to a dir containing the images and not to the images themselves\n    path = aug_dir\n    save_path = 'base_dir/train_dir/' + img_class\n\n    # Create a data generator\n    datagen = ImageDataGenerator(\n        rotation_range=180,\n        width_shift_range=0.1,\n        height_shift_range=0.1,\n        zoom_range=0.1,\n        horizontal_flip=True,\n        vertical_flip=True,\n        #brightness_range=(0.9,1.1),\n        fill_mode='nearest')\n\n    batch_size = 50\n\n    aug_datagen = datagen.flow_from_directory(path,\n                                           save_to_dir=save_path,\n                                           save_format='jpg',\n                                                    target_size=(224,224),\n                                                    batch_size=batch_size)\n\n\n\n    # Generate the augmented images and add them to the training folders\n    \n    ###########\n    \n    num_aug_images_wanted = 6000 # total number of images we want to have in each class\n    \n    ###########\n    \n    num_files = len(os.listdir(img_dir))\n    num_batches = int(np.ceil((num_aug_images_wanted-num_files)/batch_size))\n\n    # run the generator and create about 6000 augmented images\n    for i in range(0,num_batches):\n\n        imgs, labels = next(aug_datagen)\n        \n    # delete temporary directory with the raw image files\n    shutil.rmtree('aug_dir')","metadata":{"_uuid":"27d7a80b6388e75ebe6647b6cb0ea147ca82d9b4","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# checking count of images in each class after augmentation","metadata":{"_uuid":"592edd5c5c25055d537b4855f220e36bdeedd7fb"}},{"cell_type":"code","source":"# Check how many train images we now have in each folder.\n# This is the original images plus the augmented images.\n\nprint(len(os.listdir('base_dir/train_dir/nv')))\nprint(len(os.listdir('base_dir/train_dir/mel')))\nprint(len(os.listdir('base_dir/train_dir/bkl')))\nprint(len(os.listdir('base_dir/train_dir/bcc')))\nprint(len(os.listdir('base_dir/train_dir/akiec')))\nprint(len(os.listdir('base_dir/train_dir/vasc')))\nprint(len(os.listdir('base_dir/train_dir/df')))","metadata":{"_uuid":"b5873ea221f004d33b10657c59ca7f26b39ef943","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check how many val images we have in each folder.\n\nprint(len(os.listdir('base_dir/val_dir/nv')))\nprint(len(os.listdir('base_dir/val_dir/mel')))\nprint(len(os.listdir('base_dir/val_dir/bkl')))\nprint(len(os.listdir('base_dir/val_dir/bcc')))\nprint(len(os.listdir('base_dir/val_dir/akiec')))\nprint(len(os.listdir('base_dir/val_dir/vasc')))\nprint(len(os.listdir('base_dir/val_dir/df')))","metadata":{"_uuid":"d2caa0f96c73560aacb973d8e239b283eba83463","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# visualizing the augmented images","metadata":{"_uuid":"baac23521269d09bc27dcac7b9e31cd71f4e8a46"}},{"cell_type":"code","source":"# plots images with labels within jupyter notebook\n# source: https://github.com/smileservices/keras_utils/blob/master/utils.py\n\ndef plots(ims, figsize=(12,6), rows=5, interp=False, titles=None): # 12,6\n    if type(ims[0]) is np.ndarray:\n        ims = np.array(ims).astype(np.uint8)\n        if (ims.shape[-1] != 3):\n            ims = ims.transpose((0,2,3,1))\n    f = plt.figure(figsize=figsize)\n    cols = len(ims)//rows if len(ims) % 2 == 0 else len(ims)//rows + 1\n    for i in range(len(ims)):\n        sp = f.add_subplot(rows, cols, i+1)\n        sp.axis('Off')\n        if titles is not None:\n            sp.set_title(titles[i], fontsize=16)\n        plt.imshow(ims[i], interpolation=None if interp else 'none')\n        \nplots(imgs, titles=None) # titles=labels will display the image labels","metadata":{"_uuid":"a2f4f7610656b6a6479a2416e3231b52ae46d2f0","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = 'base_dir/train_dir/mel'\nprint(len(os.listdir(data)))\nda = os.listdir(data)\nimg = da[0]\nimport cv2 as cv\nprint(img)\nimag = cv.imread(img)\nprint(imag)","metadata":{"_uuid":"b24a1aad8160041af4b3ce81973593040480e714","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# creating data pipelines","metadata":{"_uuid":"a03843a3934e1d865c7193ee370e46c00048d7fe"}},{"cell_type":"code","source":"train_path = 'base_dir/train_dir'\nvalid_path = 'base_dir/val_dir'\n\nnum_train_samples = len(df_train)\nnum_val_samples = len(df_val)\ntrain_batch_size = 10\nval_batch_size = 10\nimage_size = 224\n\ntrain_steps = np.ceil(num_train_samples / train_batch_size)\nval_steps = np.ceil(num_val_samples / val_batch_size)","metadata":{"_uuid":"6fd5e5e1a28e887d31b1aa331be8fe375048c141","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndatagen = ImageDataGenerator(\n    preprocessing_function= \\\n    tensorflow.keras.applications.mobilenet.preprocess_input)\n\ntrain_batches = datagen.flow_from_directory(train_path,\n                                            target_size=(image_size,image_size),\n                                            batch_size=train_batch_size)\n\nvalid_batches = datagen.flow_from_directory(valid_path,\n                                            target_size=(image_size,image_size),\n                                            batch_size=val_batch_size)\n\n# Note: shuffle=False causes the test dataset to not be shuffled\ntest_batches = datagen.flow_from_directory(valid_path,\n                                            target_size=(image_size,image_size),\n                                            batch_size=1,\n                                            shuffle=False)","metadata":{"_uuid":"eca4eaab7528515350eb6650e672c595eb7e58a8","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Customising mobile net","metadata":{"_uuid":"f5b4994eb1a1eeee7ef69e40f9813ee73cb3bbe8"}},{"cell_type":"code","source":"mobile = tensorflow.keras.applications.mobilenet.MobileNet()","metadata":{"_uuid":"734e457921a7c9ab75df187c78cb642877068def","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mobile.summary()","metadata":{"_uuid":"930c6447114e37483a9543d20d666288a532dd28","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"type(mobile.layers)","metadata":{"_uuid":"7999a51002ae496dbea27d5322c120a7c5d0e8a3","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(mobile.layers)","metadata":{"_uuid":"b31cff094b7ff51db8f442f44f10292fa4b57224","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# CREATE THE MODEL ARCHITECTURE\n\n# Exclude the last 5 layers of the above model.\n# This will include all layers up to and including global_average_pooling2d_1\nx = mobile.layers[-6].output\n\n# Create a new dense layer for predictions\n# 7 corresponds to the number of classes\nx = Dropout(0.25)(x)\npredictions = Dense(7, activation='softmax')(x)\n\n# inputs=mobile.input selects the input layer, outputs=predictions refers to the\n# dense layer we created above.\n\nmodel = Model(inputs=mobile.input, outputs=predictions)","metadata":{"_uuid":"79089de3e005e69e39342ff36fc890ec481b0944","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"_uuid":"5bd28affd98a39020b7651854cb2e2310eef3e0a","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# We need to choose how many layers we actually want to be trained.\n\n# Here we are freezing the weights of all layers except the\n# last 23 layers in the new model.\n# The last 23 layers of the model will be trained.\n\nfor layer in model.layers[:-23]:\n    layer.trainable = False","metadata":{"_uuid":"7131c5001e9803b3e652e2bcbfaa6739b0092a17","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# training the defined model","metadata":{"_uuid":"eca4ffbd145d2194078130208bd1b4319239da16"}},{"cell_type":"code","source":"# Define Top2 and Top3 Accuracy\n\nfrom tensorflow.keras.metrics import categorical_accuracy, top_k_categorical_accuracy\n\ndef top_3_accuracy(y_true, y_pred):\n    return top_k_categorical_accuracy(y_true, y_pred, k=3)\n\ndef top_2_accuracy(y_true, y_pred):\n    return top_k_categorical_accuracy(y_true, y_pred, k=2)","metadata":{"_uuid":"c72133bdc0e7e81528d3c07966acdb2734156d6b","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(Adam(lr=0.01), loss='categorical_crossentropy', \n              metrics=[categorical_accuracy, top_2_accuracy, top_3_accuracy])\n\n","metadata":{"_uuid":"644090e8f1205c525904f7bc89bde1af9aa6c25f","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get the labels that are associated with each index\nprint(valid_batches.class_indices)","metadata":{"_uuid":"7638f1d193e0ede6ef7c6a3ec135641f373d8887","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Add weights to try to make the model more sensitive to melanoma\n\nclass_weights={\n    0: 1.0, # akiec\n    1: 1.0, # bcc\n    2: 1.0, # bkl\n    3: 1.0, # df\n    4: 3.0, # mel # Try to make the model more sensitive to Melanoma.\n    5: 1.0, # nv\n    6: 1.0, # vasc\n}","metadata":{"_uuid":"98ab1a4f404a439a1152e78ec7f2e7869b2ba95c","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data fitting and Minor tweaks to increase learning process","metadata":{"_uuid":"84342c6ef533a3e5fb7e9ed8aa5d857090ce3b76"}},{"cell_type":"code","source":"\nfilepath = \"model.h5\"\ncheckpoint = ModelCheckpoint(filepath, monitor='val_top_3_accuracy', verbose=1, \n                             save_best_only=True, mode='max')\n\nreduce_lr = ReduceLROnPlateau(monitor='val_top_3_accuracy', factor=0.5, patience=2, \n                                   verbose=1, mode='max', min_lr=0.00001)\n                              \n                              \ncallbacks_list = [checkpoint, reduce_lr]\n\nhistory = model.fit_generator(train_batches, steps_per_epoch=train_steps, \n                              class_weight=class_weights,\n                    validation_data=valid_batches,\n                    validation_steps=val_steps,\n                    epochs=30, verbose=1,\n                   callbacks=callbacks_list)\n","metadata":{"_uuid":"d749fe18f05198004454d211acc0ac5f306819ea","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Evaluating the obtained model","metadata":{"_uuid":"f39f463657f326d7d9374dfc5ced2f49ba24f1c9"}},{"cell_type":"code","source":"# get the metric names so we can use evaulate_generator\nmodel.metrics_names","metadata":{"_uuid":"c040645cd031efeb6bc6c17b706e216b376aeb30","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Here the the last epoch will be used.\n\nval_loss, val_cat_acc, val_top_2_acc, val_top_3_acc = \\\nmodel.evaluate_generator(test_batches, \n                        steps=len(df_val))\n\nprint('val_loss:', val_loss)\nprint('val_cat_acc:', val_cat_acc)\nprint('val_top_2_acc:', val_top_2_acc)\nprint('val_top_3_acc:', val_top_3_acc)","metadata":{"_uuid":"83e83c88579edf21c860c284844c51a76b40efe0","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Here the best epoch will be used.\n\nmodel.load_weights('model.h5')\n\nval_loss, val_cat_acc, val_top_2_acc, val_top_3_acc = \\\nmodel.evaluate_generator(test_batches, \n                        steps=len(df_val))\n\nprint('val_loss:', val_loss)\nprint('val_cat_acc:', val_cat_acc)\nprint('val_top_2_acc:', val_top_2_acc)\nprint('val_top_3_acc:', val_top_3_acc)","metadata":{"_uuid":"1c66e16c800c27b798937e6cce8b3baf173a69f0","trusted":true},"execution_count":null,"outputs":[]}]}